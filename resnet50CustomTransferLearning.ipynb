{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## All Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/rabel/anaconda3/lib/python3.6/site-packages/h5py/__init__.py:36: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  from ._conv import register_converters as _register_converters\n",
      "Using TensorFlow backend.\n",
      "/home/rabel/anaconda3/lib/python3.6/site-packages/sklearn/cross_validation.py:41: DeprecationWarning: This module was deprecated in version 0.18 in favor of the model_selection module into which all the refactored classes and functions are moved. Also note that the interface of the new CV iterators are different from that of this module. This module will be removed in 0.20.\n",
      "  \"This module will be removed in 0.20.\", DeprecationWarning)\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import os\n",
    "import time\n",
    "from resnet50 import ResNet50\n",
    "from keras.preprocessing import image\n",
    "from keras.layers import GlobalAveragePooling2D, Dense, Dropout,Activation,Flatten\n",
    "\n",
    "from imagenet_utils import preprocess_input\n",
    "from keras.layers import Input\n",
    "from keras.models import Model\n",
    "from keras.utils import np_utils\n",
    "from sklearn.utils import shuffle\n",
    "from sklearn.cross_validation import train_test_split"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Priting Shape for Single Image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(224, 224, 3)\n",
      "(1, 224, 224, 3)\n",
      "Input image shape:  (1, 224, 224, 3)\n"
     ]
    }
   ],
   "source": [
    "img_path = 'cat_1.jpg'\n",
    "img = image.load_img(img_path, target_size=(224, 224))\n",
    "\n",
    "x = image.img_to_array(img)\n",
    "print(x.shape)\n",
    "\n",
    "x = np.expand_dims(x, axis=0)\n",
    "print(x.shape)\n",
    "\n",
    "x = preprocess_input(x)\n",
    "print('Input image shape: ', x.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Setting dataset directory Path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['horses', 'Humans', 'dogs', 'cats']\n"
     ]
    }
   ],
   "source": [
    "PATH = '/home/rabel/Downloads/Gallery/Transafer Learning/resNet50/Transfer-Learning-in-keras/'\n",
    "data_path = PATH + 'data'\n",
    "data_dir_list = os.listdir(data_path)\n",
    "print(data_dir_list)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Loading Dataset in a single list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "========Loaded the images of dataset-horses=========\n",
      "\n",
      "========Loaded the images of dataset-Humans=========\n",
      "\n",
      "========Loaded the images of dataset-dogs=========\n",
      "\n",
      "========Loaded the images of dataset-cats=========\n",
      "\n",
      "All Images are appended\n",
      "Total imgages: 808\n"
     ]
    }
   ],
   "source": [
    "img_data_list = []\n",
    "\n",
    "for dataset in data_dir_list:\n",
    "    img_list = os.listdir(data_path + '/' + dataset)\n",
    "    print ('========Loaded the images of dataset-'+'{}=========\\n'.format(dataset))\n",
    "    for img in img_list:\n",
    "        img_path = data_path + '/' + dataset + '/' + img\n",
    "        img = image.load_img(img_path, target_size=(224, 224))\n",
    "        x = image.img_to_array(img)\n",
    "        x = np.expand_dims(x, axis = 0)\n",
    "        x = preprocess_input(x)\n",
    "        #print('Input image shape:', x.shape)\n",
    "        img_data_list.append(x)\n",
    "print('All Images are appended')\n",
    "print('Total imgages:', len(img_data_list))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(808, 1, 224, 224, 3)\n",
      "(1, 808, 224, 224, 3)\n",
      "(808, 224, 224, 3)\n"
     ]
    }
   ],
   "source": [
    "img_data = np.array(img_data_list)\n",
    "print(img_data.shape)\n",
    "img_data = np.rollaxis(img_data, 1, 0)\n",
    "print(img_data.shape)\n",
    "img_data = img_data[0]\n",
    "print(img_data.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###  Define the number of classes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_classes = 4\n",
    "num_of_samples = img_data.shape[0]\n",
    "labels = np.ones((num_of_samples,),dtype='int64')\n",
    "labels[0:202] = 0\n",
    "labels[202:404] = 1\n",
    "labels[404:606] = 2\n",
    "labels[606:] = 3\n",
    "names = ['cats','dogs','horses','humans']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[1. 0. 0. 0.]\n",
      " [1. 0. 0. 0.]\n",
      " [1. 0. 0. 0.]\n",
      " ...\n",
      " [0. 0. 0. 1.]\n",
      " [0. 0. 0. 1.]\n",
      " [0. 0. 0. 1.]]\n"
     ]
    }
   ],
   "source": [
    "# convert class labels to on-hot encoding\n",
    "Y = np_utils.to_categorical(labels, num_classes)\n",
    "print(Y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Shuffling and Spliting dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X_train 646\n",
      "X_test 162\n",
      "y_train 646\n",
      "y_test 162\n"
     ]
    }
   ],
   "source": [
    "#Shuffle the dataset\n",
    "x, y = shuffle(img_data, Y, random_state = 2)\n",
    "# Split the dataset\n",
    "X_train, X_test, y_train, y_test = train_test_split(x, y, test_size=0.2, random_state=2)\n",
    "print('X_train', len(X_train))\n",
    "print('X_test', len(X_test))\n",
    "print('y_train', len(y_train))\n",
    "print('y_test', len(y_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Custom_resnet_model_1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "_obtain_input_shape() got an unexpected keyword argument 'include_top'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-9-ce1ab453790c>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mimage_input\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mInput\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m224\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m224\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m3\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0mmodel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mResNet50\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput_tensor\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mimage_input\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minclude_top\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mweights\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'imagenet'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      4\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msummary\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mlast_layer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_layer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'avg_pool'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moutput\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Downloads/Gallery/Transafer Learning/resNet50/Transfer-Learning-in-keras/resnet50.py\u001b[0m in \u001b[0;36mResNet50\u001b[0;34m(include_top, weights, input_tensor, input_shape, pooling, classes)\u001b[0m\n\u001b[1;32m    178\u001b[0m                                       \u001b[0mmin_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m197\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    179\u001b[0m                                       \u001b[0mdata_format\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mK\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mimage_data_format\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 180\u001b[0;31m                                       include_top= 'require_flatten')\n\u001b[0m\u001b[1;32m    181\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    182\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0minput_tensor\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mTypeError\u001b[0m: _obtain_input_shape() got an unexpected keyword argument 'include_top'"
     ]
    }
   ],
   "source": [
    "image_input = Input(shape=(224, 224, 3))\n",
    "\n",
    "model = ResNet50(input_tensor=image_input, include_top=True,weights='imagenet')\n",
    "model.summary()\n",
    "last_layer = model.get_layer('avg_pool').output\n",
    "x = Flatten(name='flatten')(last_layer)\n",
    "out = Dense(num_classes, activation='softmax', name='output_layer')(x)\n",
    "custom_resnet_model = Model(inputs=image_input,outputs= out)\n",
    "custom_resnet_model.summary()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
